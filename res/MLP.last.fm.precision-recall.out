MLP arguments: Namespace(batch_size=256, dataset='last.fm.precision-recall', epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.001, num_neg=4, out=1, path='Data/', precisionK=500, recallK=300, recall_precision=True, reg_layers='[0,0,0,0]', topK=10, verbose=1) 
Load data done [0.7 s]. #user=1860, #item=17624, #train=18600, #test=1860
Init: Recall = 0.0021, Precision = 0.0154	 [251.6 s]
Iteration 0 [40.1 s]: Recall = 0.0369, Precision = 0.3840, loss = 0.4435 [18.4 s]
Iteration 1 [1.9 s]: Recall = 0.0369, Precision = 0.3829, loss = 0.3141 [18.4 s]
Iteration 2 [2.0 s]: Recall = 0.0372, Precision = 0.3851, loss = 0.2812 [18.5 s]
Iteration 3 [1.8 s]: Recall = 0.0371, Precision = 0.3885, loss = 0.2566 [18.7 s]
Iteration 4 [1.8 s]: Recall = 0.0367, Precision = 0.3880, loss = 0.2413 [18.6 s]
Iteration 5 [1.8 s]: Recall = 0.0368, Precision = 0.3923, loss = 0.2357 [18.6 s]
Iteration 6 [1.9 s]: Recall = 0.0374, Precision = 0.3937, loss = 0.2263 [18.2 s]
Iteration 7 [1.9 s]: Recall = 0.0376, Precision = 0.3956, loss = 0.2208 [18.6 s]
Iteration 8 [2.1 s]: Recall = 0.0378, Precision = 0.4015, loss = 0.2094 [18.8 s]
Iteration 9 [2.4 s]: Recall = 0.0376, Precision = 0.4024, loss = 0.2042 [18.7 s]
Iteration 10 [2.7 s]: Recall = 0.0378, Precision = 0.4053, loss = 0.1950 [19.1 s]
Iteration 11 [3.0 s]: Recall = 0.0373, Precision = 0.4028, loss = 0.1889 [19.2 s]
Iteration 12 [3.6 s]: Recall = 0.0373, Precision = 0.4043, loss = 0.1786 [19.1 s]
Iteration 13 [4.4 s]: Recall = 0.0364, Precision = 0.4004, loss = 0.1676 [19.3 s]
Iteration 14 [5.4 s]: Recall = 0.0358, Precision = 0.3952, loss = 0.1570 [19.3 s]
Iteration 15 [6.3 s]: Recall = 0.0356, Precision = 0.3834, loss = 0.1480 [19.4 s]
Iteration 16 [7.2 s]: Recall = 0.0352, Precision = 0.3758, loss = 0.1390 [19.4 s]
Iteration 17 [7.9 s]: Recall = 0.0361, Precision = 0.3858, loss = 0.1322 [19.4 s]
Iteration 18 [8.9 s]: Recall = 0.0349, Precision = 0.3695, loss = 0.1254 [19.6 s]
Iteration 19 [9.0 s]: Recall = 0.0360, Precision = 0.3783, loss = 0.1187 [19.4 s]
End. Best Iteration 8:  Recall = 0.0378, Precision = 0.4015. 
The best MLP model is saved to Pretrain/last.fm.precision-recall_MLP_[64,32,16,8]_1596295367.h5
